pop_data
# ExercÃ­cio 1 - Construa o dataset pop_data com os dados de voos das
# companhias aÃ©reas UA (United Airlines) e DL (Delta Airlines).
# O dataset deve conter apenas duas colunas, nome da companhia e atraso nos voos de chegada.
# Os dados devem ser extraÃ­dos do dataset flights para construir o dataset pop_data
# Vamos considerar este dataset como sendo nossa populaÃ§Ã£o de voos
pop_data <- filter(flights, carrier == 'UA' | carrier == 'DL')
pop_data <- pop_data[, c('carrier', 'arr_delay')] %>% filter(pop_data, arr_delay > 0) %>% sample_n(15000)
pop_data <- pop_data[, c('carrier', 'arr_delay')] %>% filter(arr_delay > 0) %>% sample_n(15000)
pop_data
str(pop_data)
class(pop_data)
DL <- subset(pop_data, carrier == 'DL' )
DL <- subset(pop_data, carrier == 'DL') %>% sample_n(1000)
UA <- subset(pop_data, carrier = 'UA') %>% sample_n(1000)
# ExercÃ­cio 2  - Crie duas amostras de 1000 observaÃ§Ãµes cada uma a partir do
# dataset pop_data apenas com dados da companhia DL para amostra 1 e apenas dados
# da companhia UA na amostra 2
# Dica: inclua uma coluna chamada sample_id preenchida com nÃºmero 1 para a primeira
# amostra e 2 para a segunda amostra
pop_data$sample_id <- ifelse(pop_data$carrier == 'DL', 1, 2)
DL <- subset(pop_data, carrier == 'DL') %>% sample_n(1000)
UA <- subset(pop_data, carrier = 'UA') %>% sample_n(1000)
# ExercÃ­cio 3 - Crie um dataset contendo os dados das 2 amostras criadas no item anterior.
sample <- rbind(DL, UA)
View(sample)
# Erro padrÃ£o
erro_padrao_sample = sd(sample$arr_delay) / sqrt(nrow(sample))
# Limites inferior e superior
# 1.96 Ã© o valor de z score para 95% de confianÃ§a
lower = mean(sample$arr_delay) - 1.96 * erro_padrao_sample
upper = mean(sample$arr_delay) + 1.96 * erro_padrao_sample
mean(sample$arr_delay)
# Intervalo de confianÃ§a
ic_1 = c(lower, upper)
ic_1
mean(DL$arr_delay)
# Erro padrÃ£o
erro_padrao_DL = sd(DL$arr_delay) / sqrt(nrow(DL))
# Limites inferior e superior
# 1.96 Ã© o valor de z score para 95% de confianÃ§a
lower = mean(DL$arr_delay) - 1.96 * erro_padrao_DL
upper = mean(DL$arr_delay) + 1.96 * erro_padrao_DL
# Intervalo de confianÃ§a
ic_1 = c(lower, upper)
mean(DL$arr_delay)
ic_1
# ExercÃ­cio 5 - Calcule o intervalo de confianÃ§a (95%) da amostra2
erro_padrao_UA = sd(UA$arr_delay) / sqrt(nrow(UA))
# ExercÃ­cio 5 - Calcule o intervalo de confianÃ§a (95%) da amostra2
erro_padrao_UA = sd(UA$arr_delay) / sqrt(nrow(UA))
# Limites inferior e superior
# 1.96 Ã© o valor de z score para 95% de confianÃ§a
lower1 = mean(UA$arr_delay) - 1.96 * erro_padrao_UA
upper1 = mean(UA$arr_delay) + 1.96 * erro_padrao_UA
# Intervalo de confianÃ§a
ic_1 = c(lower1, upper1)
mean(UA$arr_delay)
ic_1
# ExercÃ­cio 6 - Crie um plot Visualizando os intervalos de confianÃ§a criados nos itens anteriores
# Dica: Use o geom_point() e geom_errorbar() do pacote ggplot2
toplot <- summarise(group_by(DL, UA), mean = mean(arr_delay))
ic_2 = c(lower1, upper1)
mean(UA$arr_delay)
ic_2
ic_1 = c(lower, upper)
mean(DL$arr_delay)
ic_1
toplot <- summarise(group_by(DL, UA), mean = mean(arr_delay))
toplot <- mutate(toplot, lower = ifelse(toplot$sample_id == 1, ic_1[1], ic_2[1]))
toplot <- mutate(toplot, upper = ifelse(toplot$sample_id == 1, ic_1[2], ic_2[2]))
ggplot(toplot, aes(x = sample_id, y=mean, colour = sample_id)) + geom_point() + geom_errorbar(aes(ymin = lower, ymax = upper), width = 1)
toplot = summarise(group_by(DL, UA), mean = mean(arr_delay))
toplot = mutate(toplot, lower = ifelse(toplot$sample_id == 1, ic_1[1], ic_2[1]))
toplot = mutate(toplot, upper = ifelse(toplot$sample_id == 1, ic_1[2], ic_2[2]))
ggplot(toplot, aes(x = sample_id, y=mean, colour = sample_id)) + geom_point() + geom_errorbar(aes(ymin = lower, ymax = upper), width = 1)
toplot = summarise(group_by(sample, sample_id), mean = mean(arr_delay))
toplot = mutate(toplot, lower = ifelse(toplot$sample_id == 1, ic_1[1], ic_2[1]))
toplot = mutate(toplot, upper = ifelse(toplot$sample_id == 1, ic_1[2], ic_2[2]))
ggplot(toplot, aes(x = sample_id, y=mean, colour = sample_id)) + geom_point() + geom_errorbar(aes(ymin = lower, ymax = upper), width = 1)
dados <- read.csv('D:/Data Science/DSA/R com Azure/08 - Machine Learning/dados.csv')
str(dados)
x <- filter(dados$Tipo_Imovel <> 'Apartamento')
bd <- filter(dados, Tipo_Imovel <> 'Apartamento')
bd <- filter(dados, Tipo_Imovel == !'Apartamento')
bd <- filter(dados, Tipo_Imovel != 'Apartamento')
bd <- filter(dados, Tipo_Imovel != 'Apartamento')
bd <- filter(dados, Tipo_Imovel != 'Apartamento')
View(dados)
bd <- filter(dados, Tipo_Imovel != 'Apartamento')
names(dados)
bd <- filter(dados, Tipo_Imovel != 'Apartamento')
bd <- filter(dados$Tipo_Imovel != 'Apartamento')
bd <- dados[dados$Tipo_Imovel != 'Apartamento', ]
View(bd)
x = bd[bd$Status_Imovel, ]
y = bd[bd$Status_Imovel, ]
table(x,y)
df <- table(x,y)
prop.table(table(x,y))
x = bd$Status_Imovel
y = bd$Status_Imovel
table(x,y)
?chisq.test
chisq.test(x, y)
x = bd$Tipo_Imovel
table(x,y)
chisq.test(x, y)
# Criando a massa de dados (apesar de aleatória, y possui
# uma relação com os dados de x)
x <- seq(0, 100)
y <- 2 * x + 35
# Imprimindo as variáveis
x
y
# Gerando uma distribuição normal
y1 <- y + rnorm(101, 0, 50)
y1
hist(y1)
?rnorm
# Crie um plot do relacionamento de x e y1
library(ggplot2)
?ggplot
sample <- data.frame(c(x, y, y1))
View(sample)
sample <- data.frame(x, y, y1)
View(sample)
library(hrbrthemes)
install.packages('hrbrthemes')
library(hrbrthemes)
ggplot(sample, aes(x = x, y = y1)) + geom_point() + geom_smooth(method=lm , color="red", fill="#69b3a2", se=TRUE) +
theme_ipsum()
?lm
# Crie um modelo de regressão para as duas variáveis x e y1
modelo <- lm(x~y, sample)
# Capture os coeficentes
summary(modelo)
# Visualize a linha de regressão
plot(x, y1, sample, main = 'Gráfico de Dispersão', xlab = 'X', ylab = 'Y')
# Visualize a linha de regressão
plot(x, y1, main = 'Gráfico de Dispersão', xlab = 'X', ylab = 'Y')
abline(modelo, col ='red')
# Simulando outras possíveis linhas de regressão
y3 <- (y2[51]-50*(b-1))+(b-1)*x
y2 <- a + b*x
# Simulando outras possíveis linhas de regressão
y3 <- (y1[51]-50*(b-1))+(b-1)*x
coeficientes <- coef(modelo)
# Crie um modelo de regressão para as duas variáveis x e y1
modelo <- lm(y ~ x, sample)
# Capture os coeficentes
summary(modelo)
# Crie um modelo de regressão para as duas variáveis x e y1
modelo <- lm(y ~ x + y1, sample)
# Capture os coeficentes
summary(modelo)
coeficientes <- coef(modelo)
y2 <- a + bx*x + by1*y1
# Fórmula de Regressão
a <- coeficientes[1]
bx <- coeficientes[2]
by1 <- coeficientes[3]
y2 <- a + bx*x + by1*y1
# Visualize a linha de regressão
plot(modelo, main = 'Gráfico de Dispersão', xlab = 'X', ylab = 'Y1')
# Visualize a linha de regressão
plot(modelo, main = 'Gráfico de Dispersão', xlab = 'X', ylab = 'Y1')
abline(modelo, col ='red')
# Visualize a linha de regressão
par(mfrow = c(2, 2))
plot(modelo, main = 'Gráfico de Dispersão')
ggplot(sample, aes(x = x, y = y1)) + geom_point()
# Criando a massa de dados (apesar de aleatória, y possui
# uma relação com os dados de x)
x <- seq(0, 100)
function (x, size, replace = FALSE, prob = NULL)
y <- 2 * x + 35
y <- 2 * x + 35
# Imprimindo as variáveis
x
y
?seq
# Gerando uma distribuição normal
y1 <- y + rnorm(101, 0, 50)
y1
# Definindo o diretório de trabalho
setwd("D:/Data Science/Projetos/R com Azure/Projetos-em-linguagem-R-com-Azure/Classificacao_Best_Sellers_Amazon")
getwd()
# Carregando as bibliotecas
library(dplyr)
library(ggplot2)
library(readxl)
library(Amelia)
library(caTools)
library(class)
library(randomForest)
library(e1071)
library(pROC)
library(nnet)
# Carregando o dataset, disponível em: https://www.kaggle.com/datasets/abdulhamidadavize/top-100-best-selling-books-on-amazon-20092021?resource=download
dados <- read_excel('Amazon_top100_bestselling_books_2009to2021.xlsx')
# Dimensões
dim(dados)
#visualizando os dados
View(dados)
# Variáveis e Tipos de Dados
str(dados)
# Sumários das variáveis numéricas
summary(dados)
################## Analise exploratória de dados ####################
# Retirando a primeira coluna com a posição do livro (ordem de raspagem)
df <- dados[, -1]
str(df)
# Nomes das colunas
colnames(df)
# Criando o cabeçalho
cabecalho <- c('Preco', 'Rank', 'Titulo', 'Review', 'Avaliacao', 'Autor', 'Capa', 'Ano', 'Genero')
cabecalho
# Renomeando o cabeçalho no dataframe
colnames(df) <- cabecalho
colnames(df)
rm(cabecalho)
# Verificando NA
missmap(df,
main = "Best-sellers - Mapa de Dados Missing",
col = c("yellow", "black"),
legend = FALSE)
# Quantas linhas tem casos completos?
complete_cases <- sum(complete.cases(df))
# Quantas linhas tem casos incompletos?
not_complete_cases <- sum(!complete.cases(df))
# Qual o percentual de dados incompletos?
percentual <- (not_complete_cases / complete_cases) * 100
percentual
rm(complete_cases)
rm(not_complete_cases)
rm(percentual)
# Verificando os livros que foram excluídos devido a falta de informação
# Verificando quantos livros únicos há no dataset
titulo <- unique(df$Titulo)
df <- na.omit(df)
titulo_sem_na <- unique(df$Titulo)
setdiff(titulo, titulo_sem_na)
rm(titulo)
rm(titulo_sem_na)
# Verificando livros duplicados
livros_repetidos <- subset(df$Titulo, duplicated(df) | duplicated(df$Titulo, fromLast = TRUE))
livros_repetidos
# Excluindo os livros repetidos e ficando com o mais recente
df_limpos <- df %>%
distinct(Titulo, .keep_all = TRUE)
# Retirando os livros com generos desconhecidos
df_limpos <- df_limpos %>%
filter(as.character(Genero) != 'unknown')
# Transformando a variável genero para binário (1 para Fiction e 0 para No Fiction)
df_limpos$Genero <- ifelse(df_limpos$Genero == 'Fiction', 1, 0)
# Transformando as strings para variável categóricas
# Variáveis para conversão
Var_cat <- c('Autor', 'Capa', 'Ano', 'Rank', 'Avaliacao')
# Convertendo as variáveis
df_limpos[, Var_cat] <- lapply(df_limpos[, Var_cat], factor)
rm(Var_cat)
str(df_limpos)
# Vizualizando os dados
ggplot(df_limpos,aes(Avaliacao)) + geom_bar(aes(fill = factor(Avaliacao)), alpha = 0.5)
ggplot(df_limpos,aes(Autor)) + geom_bar(aes(fill = factor(Autor)), alpha = 0.5)
ggplot(df_limpos, aes(Capa)) + geom_bar(aes(fill = factor(Capa)), alpha = 0.5)
ggplot(df_limpos, aes(Ano)) + geom_bar(aes(fill = factor(Ano)), alpha = 0.5)
ggplot(df_limpos,aes(Genero)) + geom_histogram(fill = 'green', color = 'black', alpha = 0.5)
# Criando um função de normalização
normalizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Normalizando
colunas_para_normalizar <- c('Preco','Review')
df_norm <- df_limpos %>%
mutate(across(all_of(colunas_para_normalizar), normalizar))
rm(colunas_para_normalizar)
str(df_norm)
##################################Machine Learning ######################################
#Separando o dataset em treino e teste
# Defina a proporção de divisão entre treino e teste
proporcao_treino <- 0.75
# Calcule o número de amostras para treino e teste
num_amostras_treino <- round(nrow(df_limpos) * proporcao_treino)
num_amostras_teste <- nrow(df_limpos) - num_amostras_treino
# Amostra índices aleatórios para treino e teste
indices_treino <- sample(seq_len(nrow(df_limpos)), size = num_amostras_treino)
indices_teste <- setdiff(seq_len(nrow(df_limpos)), indices_treino)
# Divida o dataframe em treino e teste
df_treino <- df_limpos[indices_treino, ]
df_teste <- df_limpos[indices_teste, ]
rm(num_amostras_teste)
rm(num_amostras_treino)
rm(proporcao_treino)
str(df_treino)
# Criando o modelo de Bayes
nb_model <- naiveBayes(Genero ~ . - Rank - Titulo, data = df_treino)
nb_model_v1 <- naiveBayes(Genero ~., data=df_treino)
nb_model_v2 <- naiveBayes(Genero ~. - Rank - Titulo - Avaliacao, data=df_treino)
# Visualizando o resultado
nb_model
summary(nb_model)
str(nb_model)
# Faça as Previsões
nb_test_predict <- predict(nb_model, df_teste)
nb_test_predict_v1 <- predict(nb_model_v1, df_teste)
nb_test_predict_v2 <- predict(nb_model_v1, df_teste)
# Crie a Confusion matrix
table(pred = nb_test_predict, true = df_teste$Genero)
table(pred = nb_test_predict_v1, true = df_teste$Genero)
table(pred = nb_test_predict_v2, true = df_teste$Genero)
# Média
mean(nb_test_predict == df_teste$Genero)
mean(nb_test_predict_v1 == df_teste$Genero)
mean(nb_test_predict_v2 == df_teste$Genero)
# Gerando a curva ROC
curva_roc <- roc(df_teste$Genero, as.numeric(nb_test_predict))
plot(curva_roc, main = "Curva ROC - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
curva_roc_v1 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v1))
plot(curva_roc_v1, main = "Curva ROC v1 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v1))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc <- auc(curva_roc)
cat("AUC-ROC:", auc_roc, "\n") #0.7793
auc_roc_v1 <- auc(curva_roc_v1)
cat("AUC-ROC:", auc_roc_v1, "\n") #0.7615
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7615
# Criando o modelo por Random Forest
modelo_rf <- randomForest(factor(Genero) ~ . - Rank - Titulo - Autor, data = df_treino, ntree = 100)
modelo_rf
# Faça as Previsões RF
nb_test_predict_rf <- predict(modelo_rf, df_teste)
# Crie a Confusion matrix
table(pred = nb_test_predict_rf, true = df_teste$Genero)
# Média
mean(nb_test_predict_rf == df_teste$Genero)
# Gerando a curva ROC
curva_roc_rf <- roc(df_teste$Genero, as.numeric(nb_test_predict_rf))
plot(curva_roc_rf, main = "Curva ROC - Random Forest",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc_rf <- auc(curva_roc_rf)
cat("AUC-ROC:", auc_roc_rf, "\n") #0.7094
modelo_v1 <- glm(Genero ~ Autor + Preco + Ano, family = "binomial", data = df_treino)
nb_test_predict_log_v1 <- predict(modelo_v1, df_teste)
modelo_v1 <- multinom(Genero ~ Autor + Preco + Ano, family = "binomial", data = df_treino)
nb_test_predict_log_v1 <- predict(modelo_v1, df_teste)
table(pred = nb_test_predict_log_v1, true = df_teste$Genero)
mean(nb_test_predict_log_v1 == df_teste$Genero)
curva_roc_log_v1 <- roc(df_teste$Genero, as.numeric(nb_test_predict_log_v1))
plot(curva_roc_log_v1, main = "Curva ROC - Logistica v1",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
cat("AUC-ROC:", auc_roc_log_v1, "\n") #0.7225
auc_roc_log_v1 <- auc(curva_roc_log_v1)
cat("AUC-ROC:", auc_roc_log_v1, "\n") #0.7225
# Criando o modelo logístico
modelo <- multinom(Genero ~ Autor + Avaliacao + Preco + Ano, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Crie a Confusion matrix
table(pred = nb_test_predict_log, true = df_teste$Genero)
# Média
mean(nb_test_predict_log == df_teste$Genero)
# Gerando a curva ROC
curva_roc_log <- roc(df_teste$Genero, as.numeric(nb_test_predict_log))
plot(curva_roc_log, main = "Curva ROC - Logistica",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc_log <- auc(curva_roc_log)
cat("AUC-ROC:", auc_roc_log, "\n") #0.7225
# Criando o modelo logístico
modelo <- multinom(Genero ~ Autor + Avaliacao + Preco + Ano + Rank, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Crie a Confusion matrix
table(pred = nb_test_predict_log, true = df_teste$Genero)
# Média
mean(nb_test_predict_log == df_teste$Genero)
# Gerando a curva ROC
curva_roc_log <- roc(df_teste$Genero, as.numeric(nb_test_predict_log))
plot(curva_roc_log, main = "Curva ROC - Logistica",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc_log <- auc(curva_roc_log)
cat("AUC-ROC:", auc_roc_log, "\n") #0.7384
# Criando o modelo logístico
modelo <- multinom(Genero ~ . - Titulo, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Criando o modelo logístico
modelo <- multinom(Genero ~ . - Titulo - Review, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Criando o modelo logístico
modelo <- multinom(Genero ~ . - Titulo - Review - Capa, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Criando o modelo logístico
modelo <- multinom(Genero ~ Autor + Preco + Ano + Avaliacao + Rank + Capa, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Crie a Confusion matrix
table(pred = nb_test_predict_log, true = df_teste$Genero)
# Média
mean(nb_test_predict_log == df_teste$Genero)
# Gerando a curva ROC
curva_roc_log <- roc(df_teste$Genero, as.numeric(nb_test_predict_log))
plot(curva_roc_log, main = "Curva ROC - Logistica",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc_log <- auc(curva_roc_log)
cat("AUC-ROC:", auc_roc_log, "\n") #0.7384
# Criando o modelo logístico
modelo <- multinom(Genero ~ Autor + Preco + Ano + Avaliacao + Rank + Capa + Review, family = "binomial", data = df_treino)
# Faça as Previsões RF
nb_test_predict_log <- predict(modelo, df_teste)
# Crie a Confusion matrix
table(pred = nb_test_predict_log, true = df_teste$Genero)
# Média
mean(nb_test_predict_log == df_teste$Genero)
# Gerando a curva ROC
curva_roc_log <- roc(df_teste$Genero, as.numeric(nb_test_predict_log))
plot(curva_roc_log, main = "Curva ROC - Logistica",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc_log <- auc(curva_roc_log)
cat("AUC-ROC:", auc_roc_log, "\n") #0.7384
# Criando o modelo por Random Forest
modelo_rf <- randomForest(factor(Genero) ~ . - Titulo - Autor, data = df_treino, ntree = 100)
# Criando o modelo por Random Forest
modelo_rf <- randomForest(factor(Genero) ~ . - Review - Titulo - Autor, data = df_treino, ntree = 100)
nb_model_v2 <- naiveBayes(Genero ~. - Titulo, data=df_treino)
nb_test_predict_v2 <- predict(nb_model_v1, df_teste)
table(pred = nb_test_predict_v2, true = df_teste$Genero)
mean(nb_test_predict_v2 == df_teste$Genero)
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v1))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
# Calcular e imprimir a AUC-ROC
auc_roc <- auc(curva_roc)
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v1))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
nb_model_v2 <- naiveBayes(Genero ~ Autor + Preco + Ano , data=df_treino)
nb_test_predict_v2 <- predict(nb_model_v2, df_teste)
table(pred = nb_test_predict_v2, true = df_teste$Genero)
mean(nb_test_predict_v2 == df_teste$Genero)
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v1))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v2))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
nb_model_v2 <- naiveBayes(Genero ~ . - Titulo , data=df_treino)
nb_test_predict_v2 <- predict(nb_model_v2, df_teste)
table(pred = nb_test_predict_v2, true = df_teste$Genero)
mean(nb_test_predict_v2 == df_teste$Genero)
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v2))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v2))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
nb_model_v2 <- naiveBayes(Genero ~ . - Titulo - Rank - Capa , data=df_treino)
nb_test_predict_v2 <- predict(nb_model_v2, df_teste)
table(pred = nb_test_predict_v2, true = df_teste$Genero)
mean(nb_test_predict_v2 == df_teste$Genero)
curva_roc_v2 <- roc(df_teste$Genero, as.numeric(nb_test_predict_v2))
plot(curva_roc_v2, main = "Curva ROC v2 - Naive Bayes",
xlab = "Taxa de Falsos Positivos",
ylab = "Taxa de Verdadeiros Positivos")
auc_roc_v2 <- auc(curva_roc_v2)
cat("AUC-ROC:", auc_roc_v2, "\n") #0.7549
modelo_rf_v1 <- randomForest(factor(Genero) ~ . - Rank - Titulo - Autor, Capa, data = df_treino, ntree = 100)
modelo_rf_v1 <- randomForest(factor(Genero) ~ . - Rank - Titulo - Autor - Capa, data = df_treino, ntree = 100)
nb_test_predict_rf_v1 <- predict(modelo_rf_v1, df_teste)
table(pred = nb_test_predict_rf_v1, true = df_teste$Genero)
mean(nb_test_predict_rf_v1 == df_teste$Genero)
modelo_rf_v1 <- randomForest(factor(Genero) ~ . - Rank - Titulo - Capa, data = df_treino, ntree = 100)
